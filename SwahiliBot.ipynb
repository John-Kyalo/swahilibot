{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e5d863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f80226d57e437abfc8c35cd40ef9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "\n",
    "# Create a file upload widget\n",
    "upload_widget = FileUpload()\n",
    "\n",
    "# Display the file upload widget\n",
    "display(upload_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fd97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63871bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('swahilicleanchat.csv', 'r',encoding='utf-8') as f:\n",
    "    contents=f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a646b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  \\\n",
      "0                                           SEPTEMBA   \n",
      "1  Naitabaruku kazi hii kwa mke wangu Jemimah Kag...   \n",
      "2                                                Pia   \n",
      "3  kila nilipohitaji msaada wao. Naomba Mwenyezi ...   \n",
      "4                     busara na maneno ya kutia moyo   \n",
      "\n",
      "                                              Intent  \n",
      "0                                               2020  \n",
      "1                                      Pretty Makena  \n",
      "2  ninatoa shukrani za dhati kwa wasimamizi wangu...  \n",
      "3                                 ninamshukuru Prof.  \n",
      "4  tangu mwanzo hadi mwisho wa utafiti huu. Wengi...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('swahilicleanchat.csv', encoding='utf-8')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc9602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Message', 'Intent'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cf7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent    91\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "data = pd.read_csv('swahilicleanchat.csv')\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop('Message', axis=1)\n",
    "y = data['Intent']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check for missing values in X_train\n",
    "print(X_train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7afffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the 'Message' column with an empty string\n",
    "df['Message'].fillna(value='', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b430d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #using the punkt tokenizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae1a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = nltk.sent_tokenize(contents)\n",
    "word_tokens = nltk.word_tokenize(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14cbc2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Message,Intent\\nSEPTEMBA,2020\\nNaitabaruku kazi hii kwa mke wangu Jemimah Kagwiria na wanangu Peace Kinya,Pretty Makena\\nPia,ninatoa shukrani za dhati kwa wasimamizi wangu Prof. Ireri Mbaabu na Prof. Kitula Kingâ€™ei\\nkila nilipohitaji msaada wao.',\n",
       " 'Naomba Mwenyezi Mungu awabariki!',\n",
       " 'Aidha,ninamshukuru Prof.\\nbusara na maneno ya kutia moyo,tangu mwanzo hadi mwisho wa utafiti huu.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce4839ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Message', ',', 'Intent', 'SEPTEMBA,2020', 'Naitabaruku']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d692be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normalize and lemmatize to base form\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "  return [lemmer.lemmatize(token) for token in tokens]\n",
    "swahili_punct_dict = dict((ord(punct), None) for punct in string.punctuation )\n",
    "#remove_punct_dict =dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "  return LemTokens(nltk.word_tokenize(text.lower().translate(swahili_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2327904",
   "metadata": {},
   "outputs": [],
   "source": [
    "greet_inputs = ('vipi', 'jambo', 'hali gani', 'sema aje')\n",
    "greet_responses =('Freshi', 'Jambo', 'Salama', 'Shwari Kabisa','Sijambo')\n",
    "def greet(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower() in greet_inputs:\n",
    "      return random.choice(greet_responses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0fa6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a0ca870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "  robo1_response =''\n",
    "  swahili_stop_words = ['na','ya','kwa', 'ni', ]\n",
    "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words='english')\n",
    "  tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
    "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "  idx=vals.argsort()[0][-2]\n",
    "  flat= vals.flatten()\n",
    "  flat.sort()\n",
    "  req_tfidf = flat[-2]\n",
    "  if (req_tfidf ==0):\n",
    "    robo1_response = robo1_response + \"Samahani. Siwezi Kuelewa\"\n",
    "    return robo1_response\n",
    "  else:\n",
    "    robo1_response = robo1_response + sentence_tokens[idx]\n",
    "    return robo1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21052353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your Chatbot. Niulize maswali.\n"
     ]
    }
   ],
   "source": [
    "flag= True\n",
    "print('Hello! I am your Chatbot. Niulize maswali.')\n",
    "sentence_tokens = []\n",
    "word_tokens = []\n",
    "final_words = []\n",
    "while(flag==True):\n",
    "  user_response = input()\n",
    "  user_response = user_response.lower()\n",
    "  if (user_response !='kwaheri'):\n",
    "    if (user_response =='asante' or user_response == 'shukrani'):\n",
    "      flag= False\n",
    "      print('Bot:Karibu..')\n",
    "    else:\n",
    "      if (greet(user_response) != None):\n",
    "        print('Bot ' + greet(user_response))\n",
    "      else:\n",
    "        sentence_tokens.append(user_response)\n",
    "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
    "        final_words = list(set(word_tokens))\n",
    "        print('Bot: ', end='')\n",
    "        print(response(user_response))\n",
    "        sentence_tokens.remove(user_response)\n",
    "else:\n",
    "   flag=False\n",
    "   print('Bot: Kwaheri!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load your dataset\n",
    "dataset = pd.read_csv('swahilicleanchat.csv', encoding='utf-8')\n",
    "# Initialize variables to keep track of evaluation metrics\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "bot_responses = []\n",
    "\n",
    "# Loop through the dataset\n",
    "for index, data in dataset.iterrows():\n",
    "    # Generate a response from your chatbot\n",
    "    bot_response = response(data['Message'])\n",
    "    bot_responses.append(bot_response)\n",
    "    # Check if the response is correct\n",
    "    if bot_response == data['Intent']:\n",
    "        correct_predictions += 1\n",
    "        true_positives += 1\n",
    "    else:\n",
    "        false_positives += 1\n",
    "        false_negatives += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1_score)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report([data['answer'] for data in dataset], bot_responses)) #classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f529349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82deef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a1bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
